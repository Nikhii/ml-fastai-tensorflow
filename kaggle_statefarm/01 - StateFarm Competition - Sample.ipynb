{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# adds parent directory to python path so we can access code located there\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path: sys.path.append(nb_dir)\n",
    "    \n",
    "# core imports\n",
    "from ohmeow_ml.keras_tf_util import *\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "    \n",
    "# configure autoreload to re-load changed modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "DATA_HOME_DIR = current_dir + '/data/'\n",
    "DATA_CLASSES = [ dir for dir in os.listdir(DATA_HOME_DIR+'train') ]\n",
    "\n",
    "# path = DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR + 'sample/'\n",
    "\n",
    "train_path = path + 'train/'\n",
    "val_path = path + 'valid/'\n",
    "test_path = path + 'test/'\n",
    "\n",
    "models_path = path + 'models/'                      # save weights here\n",
    "results_path = path + 'results/'                    # save predictions here\n",
    "processed_data_path = path + 'preprocesed_data/'    # save preprocessed data used for training here\n",
    "\n",
    "if not os.path.exists(models_path): os.makedirs(models_path)\n",
    "if not os.path.exists(results_path): os.makedirs(results_path)\n",
    "if not os.path.exists(processed_data_path): os.makedirs(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4 #64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We can save time by pre-processing the images (e.g., converting them to jpegs, resizing to 224x224) and saving them as a numpy array on the file system.  We can do the same for the train, validation, and test image class designations, filenames, and one-hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 750 images belonging to 10 classes.\n",
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get classes, one-hot encoded labels, and filenames\n",
    "train_classes, train_labels, train_filenames = get_batch_info(train_path)\n",
    "val_classes, val_labels, val_filenames = get_batch_info(val_path)\n",
    "test_filenames = get_batch_info(test_path)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data loaded ...\n",
      "validation data loaded ...\n",
      "test data loaded ...\n"
     ]
    }
   ],
   "source": [
    " # get image data\n",
    "if not os.path.exists(processed_data_path+'train_data.bc'):\n",
    "    train_data = get_data(train_path)\n",
    "    save_array(processed_data_path+'train_data.bc', train_data)\n",
    "else:\n",
    "    train_data = load_array(processed_data_path+'train_data.bc')\n",
    "    print('training data loaded ...')\n",
    "\n",
    "if not os.path.exists(processed_data_path+'val_data.bc'):\n",
    "    val_data = get_data(val_path)\n",
    "    save_array(processed_data_path+'val_data.bc', val_data)\n",
    "else:\n",
    "    val_data = load_array(processed_data_path+'val_data.bc')\n",
    "    print('validation data loaded ...')\n",
    "\n",
    "if not os.path.exists(processed_data_path+'test_data.bc'):\n",
    "    test_data = get_data(test_path)\n",
    "    save_array(processed_data_path+'test_data.bc', test_data)\n",
    "else:\n",
    "    test_data = load_array(processed_data_path+'test_data.bc')\n",
    "    print('test data loaded ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training/validation batches and also define \"steps per epoch\" for each ... defines the # of batches per epoch (see `model.fit_generator()`).\n",
    "\n",
    "***ONLY RUN THIS CODE IF YOU NEED TO USE BATCHES INSTEAD OF PERSISTED IMAGE ARRAYS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OPTION 1: BUILD BATCHES FROM FILE SYSTEM\n",
    "# train_batches = get_batches(train_path, batch_size=batch_size)\n",
    "# val_batches = get_batches(val_path, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# OPTION 2: BUILD BATCHES FROM IMAGE ARRAYS\n",
    "# gen = image.ImageDataGenerator()\n",
    "# train_batches = gen.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "# val_batches = gen.flow(val_data, val_labels, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# DEFINE # OF STEPS TO TAKE IN FITTING BATCHES FOR BOTH TRAINING AND VALIDATION EXAMPLES\n",
    "# epoch_steps = math.ceil(train_batches.n/train_batches.batch_size)\n",
    "# val_steps = math.ceil(val_batches.n/val_batches.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic Models\n",
    "Train a linear classifer and a basic NN with a single hidden layer to provide a baseline and also validate that the size of our sample datasets are usable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Option 1: A simple linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lm_model():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm = lm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# IF USING BATCHES ...\n",
    "# lm.fit_generator(train_batches, steps_per_epoch=epoch_steps, epochs=2, \n",
    "#                  validation_data=val_batches, validation_steps=val_steps, verbose=2)\n",
    "\n",
    "# IF USING IMAGE ARRAYS\n",
    "lm.fit(train_data, train_labels, epochs=3, validation_data=(val_data, val_labels), shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While we have plenty of paramters (1,506,186 ~ 224\\*224\\*3\\*10 = 1505280) our accuracy is really poor (~ .13)\n",
    "\n",
    "NOTE: A **simple model with no regularization and plenty of parameters that doesn't perform well indicates that our learning rate is too high.**\n",
    "\n",
    "From the notebook: \"Perhaps it is jumping to a solution where it predicts one or two classes with high confidence so that it can give a zero prediction to as many classes as possible - that's the best approach for a model that is no better than random, and there is likely to be where we would end up with a high learning rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# IF USING BATCHES ...\n",
    "# np.round(lm.predict_generator(train_batches, epoch_steps)[:10], 2)\n",
    "\n",
    "# IF USING IMAGE ARRAYS\n",
    "np.round(lm.predict(train_data, batch_size=batch_size)[:10],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above shows that indeed, using the standard learning rate of 0.001 is too high and causing the alorithm to select 1 most of the time.  If you see this, **lower the learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 1e-05\n",
    "lm.fit(train_data, train_labels, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BEST PRACTICE: **Start with a small learning rate, then increase really high, and then decrease it gradually by a factor of 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 0.001\n",
    "lm.fit(train_data, train_labels, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 0.0001\n",
    "lm.fit(train_data, train_labels, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Option 2: A simple linear classifier with L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_lm_reg():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax', kernel_regularizer=l2(0.001))\n",
    "    ])\n",
    "    \n",
    "    model.compile(Adam(lr=10e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm = build_lm_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lm.fit(train_data, train_labels, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validate Size of Sample\n",
    "\n",
    "Once we are getting pretty consisten accuracy on our validation dataset, we should verify that our sample size is sufficient for further experiements.  If it isn't, adjust and run the previous code again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_batches = get_batches(val_path, batch_size=batch_size*2, shuffle=True)\n",
    "steps = math.ceil(rnd_batches.n / batch_size)\n",
    "val_results = [ lm.evaluate_generator(rnd_batches, steps) for i in range(10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.round(val_results, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models for Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Single Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def nn():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(Adam(lr=1e-05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=5, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizertimizer.lr = 0.01\n",
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=5, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN\n",
    "\n",
    "2 conv layers with max pooling + a simple dense network is a good simple CNN to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 750 samples\n",
      "Epoch 1/2\n",
      "62s - loss: 1.9641 - acc: 0.3380 - val_loss: 2.2936 - val_acc: 0.2533\n",
      "Epoch 2/2\n",
      "59s - loss: 1.0999 - acc: 0.6873 - val_loss: 2.3516 - val_acc: 0.2693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf77e84e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=2, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=5, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_augmentation(rotation_range=0.0, width_shift_range=0.0, height_shift_range=0.0, \n",
    "                      shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0,\n",
    "                      horizontal_flip=False, vertical_flip=False):\n",
    "    limit_mem()\n",
    "    \n",
    "    gen = image.ImageDataGenerator(\n",
    "            rotation_range=rotation_range,           # degrees (0 to 180)\n",
    "            width_shift_range=width_shift_range,     # fraction of total width\n",
    "            height_shift_range=height_shift_range,   # fraction of total height\n",
    "            shear_range=shear_range,                 # shear intensity (shear angle in radians; 2 radians = 360 degrees)\n",
    "            zoom_range=zoom_range,                   # amount of zoom\n",
    "            channel_shift_range=channel_shift_range, # shift range for each channels\n",
    "            horizontal_flip=horizontal_flip, \n",
    "            vertical_flip=vertical_flip)\n",
    "    \n",
    "    da_batches = gen.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = simple_cnn()\n",
    "    \n",
    "    epoch_steps = math.ceil(da_batches.n/da_batches.batch_size)\n",
    "    model.fit_generator(da_batches, epoch_steps, epochs=2, validation_data=(val_data, val_labels), verbose=2)\n",
    "    \n",
    "    model.optimizer.lr = 0.001\n",
    "    history = model.fit_generator(da_batches, epoch_steps, epochs=5, validation_data=(val_data, val_labels), verbose=2)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> height_shift_range = 0\n",
      "Epoch 1/2\n",
      "60s - loss: 1.9885 - acc: 0.3360 - val_loss: 2.2485 - val_acc: 0.2600\n",
      "Epoch 2/2\n",
      "58s - loss: 1.0839 - acc: 0.6833 - val_loss: 1.9539 - val_acc: 0.3587\n",
      "Epoch 1/5\n",
      "58s - loss: 0.7643 - acc: 0.8080 - val_loss: 2.0649 - val_acc: 0.3907\n",
      "Epoch 2/5\n",
      "58s - loss: 0.6019 - acc: 0.8593 - val_loss: 1.9913 - val_acc: 0.4093\n",
      "Epoch 3/5\n",
      "58s - loss: 0.4853 - acc: 0.8940 - val_loss: 1.9970 - val_acc: 0.4253\n",
      "Epoch 4/5\n",
      "59s - loss: 0.3824 - acc: 0.9307 - val_loss: 1.8117 - val_acc: 0.4280\n",
      "Epoch 5/5\n",
      "59s - loss: 0.3436 - acc: 0.9307 - val_loss: 1.7876 - val_acc: 0.4453\n",
      "> height_shift_range = 0.05\n",
      "Epoch 1/2\n",
      "61s - loss: 2.1731 - acc: 0.2813 - val_loss: 2.3515 - val_acc: 0.1773\n",
      "Epoch 2/2\n",
      "58s - loss: 1.4590 - acc: 0.5220 - val_loss: 2.3047 - val_acc: 0.2400\n",
      "Epoch 1/5\n",
      "58s - loss: 1.2011 - acc: 0.6313 - val_loss: 2.3688 - val_acc: 0.2400\n",
      "Epoch 2/5\n",
      "58s - loss: 0.9873 - acc: 0.7093 - val_loss: 2.0782 - val_acc: 0.3280\n",
      "Epoch 3/5\n",
      "59s - loss: 0.8733 - acc: 0.7427 - val_loss: 2.1689 - val_acc: 0.3413\n",
      "Epoch 4/5\n",
      "58s - loss: 0.7591 - acc: 0.7820 - val_loss: 2.0475 - val_acc: 0.4000\n",
      "Epoch 5/5\n",
      "58s - loss: 0.6306 - acc: 0.8307 - val_loss: 1.9352 - val_acc: 0.4107\n",
      "> height_shift_range = 1\n",
      "Epoch 1/2\n",
      "62s - loss: 2.6287 - acc: 0.1073 - val_loss: 2.8430 - val_acc: 0.1187\n",
      "Epoch 2/2\n",
      "59s - loss: 2.4026 - acc: 0.1513 - val_loss: 2.6837 - val_acc: 0.1040\n",
      "Epoch 1/5\n",
      "59s - loss: 2.3074 - acc: 0.1647 - val_loss: 2.8256 - val_acc: 0.1227\n",
      "Epoch 2/5\n",
      "59s - loss: 2.2563 - acc: 0.1973 - val_loss: 2.5318 - val_acc: 0.1667\n",
      "Epoch 3/5\n",
      "59s - loss: 2.2312 - acc: 0.2107 - val_loss: 2.4802 - val_acc: 0.1627\n",
      "Epoch 4/5\n",
      "59s - loss: 2.2171 - acc: 0.2147 - val_loss: 2.4341 - val_acc: 0.1987\n",
      "Epoch 5/5\n",
      "59s - loss: 2.1690 - acc: 0.2393 - val_loss: 2.3999 - val_acc: 0.1813\n",
      "> height_shift_range = 2\n",
      "Epoch 1/2\n",
      "63s - loss: 2.5849 - acc: 0.1207 - val_loss: 2.7185 - val_acc: 0.1160\n",
      "Epoch 2/2\n",
      "58s - loss: 2.3806 - acc: 0.1553 - val_loss: 3.2976 - val_acc: 0.1427\n",
      "Epoch 1/5\n",
      "58s - loss: 2.3620 - acc: 0.1500 - val_loss: 2.8798 - val_acc: 0.1293\n",
      "Epoch 2/5\n",
      "58s - loss: 2.2977 - acc: 0.1580 - val_loss: 2.8680 - val_acc: 0.1253\n",
      "Epoch 3/5\n",
      "58s - loss: 2.2600 - acc: 0.1847 - val_loss: 3.0763 - val_acc: 0.1173\n",
      "Epoch 4/5\n",
      "58s - loss: 2.2478 - acc: 0.1920 - val_loss: 3.0549 - val_acc: 0.1413\n",
      "Epoch 5/5\n",
      "58s - loss: 2.2001 - acc: 0.2200 - val_loss: 2.7409 - val_acc: 0.1440\n",
      "> height_shift_range = 4\n",
      "Epoch 1/2\n",
      "63s - loss: 2.5449 - acc: 0.1233 - val_loss: 2.8085 - val_acc: 0.1387\n",
      "Epoch 2/2\n",
      "59s - loss: 2.3465 - acc: 0.1620 - val_loss: 3.0440 - val_acc: 0.1053\n",
      "Epoch 1/5\n",
      "59s - loss: 2.2977 - acc: 0.1840 - val_loss: 4.6534 - val_acc: 0.1373\n",
      "Epoch 2/5\n",
      "59s - loss: 2.2286 - acc: 0.1973 - val_loss: 2.7816 - val_acc: 0.1240\n",
      "Epoch 3/5\n",
      "59s - loss: 2.2207 - acc: 0.2013 - val_loss: 2.6485 - val_acc: 0.1347\n",
      "Epoch 4/5\n",
      "59s - loss: 2.2046 - acc: 0.2107 - val_loss: 2.6800 - val_acc: 0.1667\n",
      "Epoch 5/5\n",
      "59s - loss: 2.1632 - acc: 0.2333 - val_loss: 2.7132 - val_acc: 0.1160\n",
      "> rotation_range = 0\n",
      "Epoch 1/2\n",
      "64s - loss: 1.9128 - acc: 0.3720 - val_loss: 2.2600 - val_acc: 0.2760\n",
      "Epoch 2/2\n",
      "59s - loss: 1.0916 - acc: 0.6853 - val_loss: 1.9211 - val_acc: 0.3547\n",
      "Epoch 1/5\n",
      "59s - loss: 0.7463 - acc: 0.8107 - val_loss: 1.9100 - val_acc: 0.3973\n",
      "Epoch 2/5\n",
      "59s - loss: 0.5805 - acc: 0.8633 - val_loss: 1.8528 - val_acc: 0.3973\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4678 - acc: 0.8980 - val_loss: 1.7938 - val_acc: 0.4387\n",
      "Epoch 4/5\n",
      "59s - loss: 0.3566 - acc: 0.9367 - val_loss: 1.8264 - val_acc: 0.4280\n",
      "Epoch 5/5\n",
      "59s - loss: 0.3151 - acc: 0.9433 - val_loss: 1.6841 - val_acc: 0.4467\n",
      "> rotation_range = 1\n",
      "Epoch 1/2\n",
      "65s - loss: 1.9948 - acc: 0.3480 - val_loss: 2.3795 - val_acc: 0.2907\n",
      "Epoch 2/2\n",
      "58s - loss: 1.1831 - acc: 0.6433 - val_loss: 2.4899 - val_acc: 0.2493\n",
      "Epoch 1/5\n",
      "59s - loss: 0.8544 - acc: 0.7640 - val_loss: 2.3749 - val_acc: 0.3000\n",
      "Epoch 2/5\n",
      "59s - loss: 0.6649 - acc: 0.8287 - val_loss: 2.2222 - val_acc: 0.3400\n",
      "Epoch 3/5\n",
      "59s - loss: 0.5216 - acc: 0.8793 - val_loss: 2.0635 - val_acc: 0.3760\n",
      "Epoch 4/5\n",
      "59s - loss: 0.4461 - acc: 0.8947 - val_loss: 2.1600 - val_acc: 0.4080\n",
      "Epoch 5/5\n",
      "59s - loss: 0.4201 - acc: 0.9040 - val_loss: 2.2218 - val_acc: 0.3813\n",
      "> rotation_range = 3\n",
      "Epoch 1/2\n",
      "65s - loss: 1.9440 - acc: 0.3440 - val_loss: 2.4649 - val_acc: 0.2600\n",
      "Epoch 2/2\n",
      "59s - loss: 1.2601 - acc: 0.6007 - val_loss: 2.2299 - val_acc: 0.2947\n",
      "Epoch 1/5\n",
      "59s - loss: 0.9229 - acc: 0.7527 - val_loss: 2.3095 - val_acc: 0.3520\n",
      "Epoch 2/5\n",
      "59s - loss: 0.7940 - acc: 0.7887 - val_loss: 2.0641 - val_acc: 0.3693\n",
      "Epoch 3/5\n",
      "59s - loss: 0.6106 - acc: 0.8387 - val_loss: 2.1154 - val_acc: 0.3733\n",
      "Epoch 4/5\n",
      "59s - loss: 0.5136 - acc: 0.8820 - val_loss: 1.8805 - val_acc: 0.4227\n",
      "Epoch 5/5\n",
      "59s - loss: 0.4785 - acc: 0.8847 - val_loss: 1.8976 - val_acc: 0.4333\n",
      "> rotation_range = 5\n",
      "Epoch 1/2\n",
      "66s - loss: 2.0469 - acc: 0.3293 - val_loss: 2.3297 - val_acc: 0.2293\n",
      "Epoch 2/2\n",
      "59s - loss: 1.3526 - acc: 0.5773 - val_loss: 2.3274 - val_acc: 0.3027\n",
      "Epoch 1/5\n",
      "59s - loss: 1.0248 - acc: 0.7033 - val_loss: 2.3096 - val_acc: 0.3307\n",
      "Epoch 2/5\n",
      "59s - loss: 0.8311 - acc: 0.7587 - val_loss: 2.3036 - val_acc: 0.3520\n",
      "Epoch 3/5\n",
      "59s - loss: 0.6887 - acc: 0.8087 - val_loss: 2.1084 - val_acc: 0.4347\n",
      "Epoch 4/5\n",
      "59s - loss: 0.5837 - acc: 0.8480 - val_loss: 2.3047 - val_acc: 0.4293\n",
      "Epoch 5/5\n",
      "59s - loss: 0.5173 - acc: 0.8740 - val_loss: 2.1665 - val_acc: 0.4200\n",
      "> rotation_range = 10\n",
      "Epoch 1/2\n",
      "67s - loss: 2.2785 - acc: 0.2360 - val_loss: 2.3962 - val_acc: 0.2213\n",
      "Epoch 2/2\n",
      "59s - loss: 1.5764 - acc: 0.4687 - val_loss: 2.3619 - val_acc: 0.3107\n",
      "Epoch 1/5\n",
      "59s - loss: 1.2794 - acc: 0.5927 - val_loss: 2.2631 - val_acc: 0.3093\n",
      "Epoch 2/5\n",
      "59s - loss: 1.0777 - acc: 0.6653 - val_loss: 2.0020 - val_acc: 0.3480\n",
      "Epoch 3/5\n",
      "59s - loss: 0.9043 - acc: 0.7367 - val_loss: 2.1103 - val_acc: 0.3707\n",
      "Epoch 4/5\n",
      "59s - loss: 0.8253 - acc: 0.7720 - val_loss: 2.0078 - val_acc: 0.4000\n",
      "Epoch 5/5\n",
      "59s - loss: 0.7325 - acc: 0.8000 - val_loss: 2.0374 - val_acc: 0.4173\n",
      "> channel_shift_range = 0\n",
      "Epoch 1/2\n",
      "68s - loss: 1.9904 - acc: 0.3240 - val_loss: 2.3403 - val_acc: 0.2427\n",
      "Epoch 2/2\n",
      "59s - loss: 1.1548 - acc: 0.6673 - val_loss: 2.2158 - val_acc: 0.2680\n",
      "Epoch 1/5\n",
      "59s - loss: 0.8654 - acc: 0.7660 - val_loss: 2.3446 - val_acc: 0.3133\n",
      "Epoch 2/5\n",
      "59s - loss: 0.6769 - acc: 0.8313 - val_loss: 2.0957 - val_acc: 0.3440\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4774 - acc: 0.9047 - val_loss: 2.0485 - val_acc: 0.3813\n",
      "Epoch 4/5\n",
      "59s - loss: 0.3929 - acc: 0.9240 - val_loss: 2.0041 - val_acc: 0.4253\n",
      "Epoch 5/5\n",
      "59s - loss: 0.3084 - acc: 0.9513 - val_loss: 1.9854 - val_acc: 0.4347\n",
      "> channel_shift_range = 10\n",
      "Epoch 1/2\n",
      "68s - loss: 1.9692 - acc: 0.3287 - val_loss: 2.3670 - val_acc: 0.2293\n",
      "Epoch 2/2\n",
      "59s - loss: 1.2378 - acc: 0.6293 - val_loss: 2.4419 - val_acc: 0.2613\n",
      "Epoch 1/5\n",
      "59s - loss: 0.8971 - acc: 0.7520 - val_loss: 2.1741 - val_acc: 0.3773\n",
      "Epoch 2/5\n",
      "59s - loss: 0.6851 - acc: 0.8407 - val_loss: 2.2064 - val_acc: 0.3520\n",
      "Epoch 3/5\n",
      "59s - loss: 0.5748 - acc: 0.8647 - val_loss: 2.1479 - val_acc: 0.3640\n",
      "Epoch 4/5\n",
      "59s - loss: 0.4971 - acc: 0.9000 - val_loss: 2.0998 - val_acc: 0.3707\n",
      "Epoch 5/5\n",
      "59s - loss: 0.4258 - acc: 0.9067 - val_loss: 2.0777 - val_acc: 0.3920\n",
      "> channel_shift_range = 20\n",
      "Epoch 1/2\n",
      "70s - loss: 1.9821 - acc: 0.3520 - val_loss: 2.4230 - val_acc: 0.2067\n",
      "Epoch 2/2\n",
      "59s - loss: 1.2486 - acc: 0.6187 - val_loss: 2.3082 - val_acc: 0.2480\n",
      "Epoch 1/5\n",
      "59s - loss: 0.8733 - acc: 0.7727 - val_loss: 2.1210 - val_acc: 0.3320\n",
      "Epoch 2/5\n",
      "59s - loss: 0.6685 - acc: 0.8473 - val_loss: 2.1264 - val_acc: 0.3800\n",
      "Epoch 3/5\n",
      "59s - loss: 0.5265 - acc: 0.8887 - val_loss: 2.1135 - val_acc: 0.3947\n",
      "Epoch 4/5\n",
      "59s - loss: 0.4726 - acc: 0.8913 - val_loss: 2.0228 - val_acc: 0.3973\n",
      "Epoch 5/5\n",
      "59s - loss: 0.3929 - acc: 0.9220 - val_loss: 2.0056 - val_acc: 0.4187\n",
      "> channel_shift_range = 30\n",
      "Epoch 1/2\n",
      "70s - loss: 2.1031 - acc: 0.2913 - val_loss: 2.2631 - val_acc: 0.2547\n",
      "Epoch 2/2\n",
      "59s - loss: 1.3038 - acc: 0.6033 - val_loss: 2.2035 - val_acc: 0.3187\n",
      "Epoch 1/5\n",
      "59s - loss: 0.9853 - acc: 0.7313 - val_loss: 2.1805 - val_acc: 0.3173\n",
      "Epoch 2/5\n",
      "59s - loss: 0.7854 - acc: 0.8007 - val_loss: 2.0402 - val_acc: 0.3787\n",
      "Epoch 3/5\n",
      "59s - loss: 0.6426 - acc: 0.8473 - val_loss: 1.9804 - val_acc: 0.3987\n",
      "Epoch 4/5\n",
      "59s - loss: 0.5090 - acc: 0.8913 - val_loss: 1.8557 - val_acc: 0.4187\n",
      "Epoch 5/5\n",
      "59s - loss: 0.4606 - acc: 0.8987 - val_loss: 1.9901 - val_acc: 0.3987\n",
      "> channel_shift_range = 50\n",
      "Epoch 1/2\n",
      "71s - loss: 2.0986 - acc: 0.2900 - val_loss: 2.2926 - val_acc: 0.2547\n",
      "Epoch 2/2\n",
      "59s - loss: 1.3192 - acc: 0.5933 - val_loss: 2.3087 - val_acc: 0.2933\n",
      "Epoch 1/5\n",
      "59s - loss: 0.9811 - acc: 0.7313 - val_loss: 2.4183 - val_acc: 0.2933\n",
      "Epoch 2/5\n",
      "59s - loss: 0.7667 - acc: 0.8073 - val_loss: 2.3166 - val_acc: 0.3107\n",
      "Epoch 3/5\n",
      "59s - loss: 0.6220 - acc: 0.8547 - val_loss: 2.2113 - val_acc: 0.3733\n",
      "Epoch 4/5\n",
      "59s - loss: 0.5149 - acc: 0.8873 - val_loss: 2.2996 - val_acc: 0.3707\n",
      "Epoch 5/5\n",
      "59s - loss: 0.4352 - acc: 0.9060 - val_loss: 2.2340 - val_acc: 0.3720\n",
      "> width_shift_range = 0\n",
      "Epoch 1/2\n",
      "72s - loss: 1.9825 - acc: 0.3467 - val_loss: 2.5471 - val_acc: 0.1760\n",
      "Epoch 2/2\n",
      "59s - loss: 1.1218 - acc: 0.6893 - val_loss: 2.7576 - val_acc: 0.2613\n",
      "Epoch 1/5\n",
      "59s - loss: 0.7590 - acc: 0.8140 - val_loss: 2.6768 - val_acc: 0.3040\n",
      "Epoch 2/5\n",
      "59s - loss: 0.6087 - acc: 0.8607 - val_loss: 2.6499 - val_acc: 0.3013\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4681 - acc: 0.8980 - val_loss: 2.8988 - val_acc: 0.3427\n",
      "Epoch 4/5\n",
      "59s - loss: 0.3639 - acc: 0.9320 - val_loss: 2.7125 - val_acc: 0.3520\n",
      "Epoch 5/5\n",
      "59s - loss: 0.2997 - acc: 0.9520 - val_loss: 2.7864 - val_acc: 0.3640\n",
      "> width_shift_range = 0.05\n",
      "Epoch 1/2\n",
      "73s - loss: 2.1372 - acc: 0.2693 - val_loss: 2.3917 - val_acc: 0.2293\n",
      "Epoch 2/2\n",
      "59s - loss: 1.5505 - acc: 0.4893 - val_loss: 2.3398 - val_acc: 0.2947\n",
      "Epoch 1/5\n",
      "59s - loss: 1.2761 - acc: 0.5987 - val_loss: 2.3363 - val_acc: 0.3067\n",
      "Epoch 2/5\n",
      "59s - loss: 1.1281 - acc: 0.6440 - val_loss: 2.3553 - val_acc: 0.3320\n",
      "Epoch 3/5\n",
      "59s - loss: 0.9582 - acc: 0.7200 - val_loss: 2.1877 - val_acc: 0.3507\n",
      "Epoch 4/5\n",
      "59s - loss: 0.8556 - acc: 0.7513 - val_loss: 2.0753 - val_acc: 0.3693\n",
      "Epoch 5/5\n",
      "59s - loss: 0.7481 - acc: 0.7867 - val_loss: 2.1407 - val_acc: 0.3933\n",
      "> width_shift_range = 1\n",
      "Epoch 1/2\n",
      "73s - loss: 2.7222 - acc: 0.1227 - val_loss: 2.9650 - val_acc: 0.1253\n",
      "Epoch 2/2\n",
      "59s - loss: 2.4395 - acc: 0.1487 - val_loss: 2.7551 - val_acc: 0.1440\n",
      "Epoch 1/5\n",
      "59s - loss: 2.3653 - acc: 0.1627 - val_loss: 2.7111 - val_acc: 0.1640\n",
      "Epoch 2/5\n",
      "59s - loss: 2.3006 - acc: 0.1780 - val_loss: 2.7695 - val_acc: 0.1787\n",
      "Epoch 3/5\n",
      "59s - loss: 2.3030 - acc: 0.1927 - val_loss: 2.7189 - val_acc: 0.1853\n",
      "Epoch 4/5\n",
      "59s - loss: 2.2689 - acc: 0.1860 - val_loss: 2.4152 - val_acc: 0.1960\n",
      "Epoch 5/5\n",
      "59s - loss: 2.2475 - acc: 0.2113 - val_loss: 2.4742 - val_acc: 0.1733\n",
      "> width_shift_range = 2\n",
      "Epoch 1/2\n",
      "73s - loss: 2.7191 - acc: 0.0993 - val_loss: 3.1345 - val_acc: 0.1093\n",
      "Epoch 2/2\n",
      "59s - loss: 2.4951 - acc: 0.1247 - val_loss: 3.0795 - val_acc: 0.1093\n",
      "Epoch 1/5\n",
      "59s - loss: 2.4173 - acc: 0.1533 - val_loss: 2.9196 - val_acc: 0.0920\n",
      "Epoch 2/5\n",
      "59s - loss: 2.3841 - acc: 0.1380 - val_loss: 2.5810 - val_acc: 0.0920\n",
      "Epoch 3/5\n",
      "59s - loss: 2.3675 - acc: 0.1613 - val_loss: 2.7746 - val_acc: 0.1107\n",
      "Epoch 4/5\n",
      "59s - loss: 2.3432 - acc: 0.1653 - val_loss: 2.5616 - val_acc: 0.1267\n",
      "Epoch 5/5\n",
      "59s - loss: 2.2992 - acc: 0.1867 - val_loss: 2.7887 - val_acc: 0.1253\n",
      "> width_shift_range = 4\n",
      "Epoch 1/2\n",
      "75s - loss: 2.6973 - acc: 0.1100 - val_loss: 3.8325 - val_acc: 0.0693\n",
      "Epoch 2/2\n",
      "59s - loss: 2.4864 - acc: 0.1267 - val_loss: 3.8118 - val_acc: 0.0867\n",
      "Epoch 1/5\n",
      "59s - loss: 2.4216 - acc: 0.1440 - val_loss: 3.2903 - val_acc: 0.0973\n",
      "Epoch 2/5\n",
      "59s - loss: 2.3663 - acc: 0.1487 - val_loss: 3.6893 - val_acc: 0.0720\n",
      "Epoch 3/5\n",
      "59s - loss: 2.3154 - acc: 0.1780 - val_loss: 3.3602 - val_acc: 0.0893\n",
      "Epoch 4/5\n",
      "59s - loss: 2.2957 - acc: 0.1767 - val_loss: 3.3155 - val_acc: 0.1133\n",
      "Epoch 5/5\n",
      "59s - loss: 2.2863 - acc: 0.1793 - val_loss: 2.9929 - val_acc: 0.1107\n",
      "> shear_range = 0\n",
      "Epoch 1/2\n",
      "76s - loss: 1.8442 - acc: 0.3927 - val_loss: 2.3666 - val_acc: 0.2827\n",
      "Epoch 2/2\n",
      "59s - loss: 1.0661 - acc: 0.6953 - val_loss: 2.1419 - val_acc: 0.3520\n",
      "Epoch 1/5\n",
      "59s - loss: 0.6990 - acc: 0.8267 - val_loss: 2.0585 - val_acc: 0.3627\n",
      "Epoch 2/5\n",
      "59s - loss: 0.5424 - acc: 0.8787 - val_loss: 2.1655 - val_acc: 0.3387\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4400 - acc: 0.9113 - val_loss: 1.9637 - val_acc: 0.4280\n",
      "Epoch 4/5\n",
      "59s - loss: 0.3346 - acc: 0.9300 - val_loss: 1.8945 - val_acc: 0.4347\n",
      "Epoch 5/5\n",
      "59s - loss: 0.2673 - acc: 0.9593 - val_loss: 1.8649 - val_acc: 0.4747\n",
      "> shear_range = 0.1\n",
      "Epoch 1/2\n",
      "76s - loss: 2.0348 - acc: 0.3333 - val_loss: 2.2887 - val_acc: 0.2867\n",
      "Epoch 2/2\n",
      "59s - loss: 1.2449 - acc: 0.6027 - val_loss: 2.0428 - val_acc: 0.3760\n",
      "Epoch 1/5\n",
      "59s - loss: 0.9428 - acc: 0.7327 - val_loss: 2.0913 - val_acc: 0.3520\n",
      "Epoch 2/5\n",
      "59s - loss: 0.7543 - acc: 0.7920 - val_loss: 2.0346 - val_acc: 0.3627\n",
      "Epoch 3/5\n",
      "59s - loss: 0.6107 - acc: 0.8460 - val_loss: 2.0002 - val_acc: 0.4320\n",
      "Epoch 4/5\n",
      "59s - loss: 0.5456 - acc: 0.8720 - val_loss: 1.9247 - val_acc: 0.4440\n",
      "Epoch 5/5\n",
      "59s - loss: 0.4647 - acc: 0.8927 - val_loss: 1.8154 - val_acc: 0.4840\n",
      "> shear_range = 0.15\n",
      "Epoch 1/2\n",
      "77s - loss: 2.0743 - acc: 0.3000 - val_loss: 2.2830 - val_acc: 0.2320\n",
      "Epoch 2/2\n",
      "59s - loss: 1.3650 - acc: 0.5587 - val_loss: 2.2821 - val_acc: 0.2920\n",
      "Epoch 1/5\n",
      "59s - loss: 1.0364 - acc: 0.6993 - val_loss: 2.2349 - val_acc: 0.3040\n",
      "Epoch 2/5\n",
      "59s - loss: 0.8183 - acc: 0.7700 - val_loss: 2.2391 - val_acc: 0.3427\n",
      "Epoch 3/5\n",
      "59s - loss: 0.7132 - acc: 0.8113 - val_loss: 2.1161 - val_acc: 0.4040\n",
      "Epoch 4/5\n",
      "59s - loss: 0.6127 - acc: 0.8407 - val_loss: 2.0062 - val_acc: 0.4080\n",
      "Epoch 5/5\n",
      "59s - loss: 0.5220 - acc: 0.8780 - val_loss: 2.2834 - val_acc: 0.3867\n",
      "> shear_range = 0.2\n",
      "Epoch 1/2\n",
      "77s - loss: 2.1287 - acc: 0.2867 - val_loss: 2.3464 - val_acc: 0.2080\n",
      "Epoch 2/2\n",
      "59s - loss: 1.4507 - acc: 0.5353 - val_loss: 2.2406 - val_acc: 0.3040\n",
      "Epoch 1/5\n",
      "59s - loss: 1.1643 - acc: 0.6633 - val_loss: 2.1197 - val_acc: 0.3053\n",
      "Epoch 2/5\n",
      "59s - loss: 0.9755 - acc: 0.7153 - val_loss: 2.0880 - val_acc: 0.3867\n",
      "Epoch 3/5\n",
      "59s - loss: 0.8163 - acc: 0.7760 - val_loss: 1.9686 - val_acc: 0.4067\n",
      "Epoch 4/5\n",
      "59s - loss: 0.6918 - acc: 0.8147 - val_loss: 2.0957 - val_acc: 0.3827\n",
      "Epoch 5/5\n",
      "59s - loss: 0.6234 - acc: 0.8393 - val_loss: 1.9397 - val_acc: 0.4107\n",
      "> shear_range = 0.3\n",
      "Epoch 1/2\n",
      "78s - loss: 2.2496 - acc: 0.2507 - val_loss: 2.5123 - val_acc: 0.2013\n",
      "Epoch 2/2\n",
      "59s - loss: 1.5732 - acc: 0.4780 - val_loss: 2.3012 - val_acc: 0.3000\n",
      "Epoch 1/5\n",
      "59s - loss: 1.2552 - acc: 0.6033 - val_loss: 2.2981 - val_acc: 0.3213\n",
      "Epoch 2/5\n",
      "59s - loss: 1.0767 - acc: 0.6767 - val_loss: 2.1788 - val_acc: 0.3253\n",
      "Epoch 3/5\n",
      "59s - loss: 0.9212 - acc: 0.7420 - val_loss: 2.2988 - val_acc: 0.3400\n",
      "Epoch 4/5\n",
      "59s - loss: 0.8305 - acc: 0.7560 - val_loss: 2.2515 - val_acc: 0.3507\n",
      "Epoch 5/5\n",
      "59s - loss: 0.7314 - acc: 0.8000 - val_loss: 2.0662 - val_acc: 0.4013\n",
      "> zoom_range = 0\n",
      "Epoch 1/2\n",
      "79s - loss: 1.9213 - acc: 0.3667 - val_loss: 2.5767 - val_acc: 0.2080\n",
      "Epoch 2/2\n",
      "59s - loss: 1.1317 - acc: 0.6607 - val_loss: 2.1696 - val_acc: 0.3413\n",
      "Epoch 1/5\n",
      "59s - loss: 0.7640 - acc: 0.8160 - val_loss: 2.1218 - val_acc: 0.3480\n",
      "Epoch 2/5\n",
      "59s - loss: 0.5428 - acc: 0.8813 - val_loss: 2.1929 - val_acc: 0.3493\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4520 - acc: 0.8953 - val_loss: 2.1413 - val_acc: 0.4053\n",
      "Epoch 4/5\n",
      "59s - loss: 0.3746 - acc: 0.9253 - val_loss: 1.9532 - val_acc: 0.4347\n",
      "Epoch 5/5\n",
      "59s - loss: 0.2902 - acc: 0.9607 - val_loss: 2.0100 - val_acc: 0.4200\n",
      "> zoom_range = 0.1\n",
      "Epoch 1/2\n",
      "79s - loss: 2.1515 - acc: 0.2753 - val_loss: 2.3099 - val_acc: 0.2427\n",
      "Epoch 2/2\n",
      "59s - loss: 1.4183 - acc: 0.5453 - val_loss: 2.2863 - val_acc: 0.3013\n",
      "Epoch 1/5\n",
      "59s - loss: 1.1140 - acc: 0.6540 - val_loss: 2.1834 - val_acc: 0.3600\n",
      "Epoch 2/5\n",
      "59s - loss: 0.9070 - acc: 0.7420 - val_loss: 2.0972 - val_acc: 0.3827\n",
      "Epoch 3/5\n",
      "59s - loss: 0.8148 - acc: 0.7740 - val_loss: 2.0588 - val_acc: 0.3867\n",
      "Epoch 4/5\n",
      "59s - loss: 0.7022 - acc: 0.8067 - val_loss: 2.1107 - val_acc: 0.3787\n",
      "Epoch 5/5\n",
      "59s - loss: 0.6066 - acc: 0.8400 - val_loss: 2.0456 - val_acc: 0.4240\n",
      "> zoom_range = 0.15\n",
      "Epoch 1/2\n",
      "81s - loss: 2.2193 - acc: 0.2600 - val_loss: 2.3077 - val_acc: 0.2600\n",
      "Epoch 2/2\n",
      "59s - loss: 1.5347 - acc: 0.4840 - val_loss: 2.4047 - val_acc: 0.3120\n",
      "Epoch 1/5\n",
      "59s - loss: 1.2485 - acc: 0.6073 - val_loss: 2.3900 - val_acc: 0.3307\n",
      "Epoch 2/5\n",
      "59s - loss: 1.0580 - acc: 0.6753 - val_loss: 2.1645 - val_acc: 0.3507\n",
      "Epoch 3/5\n",
      "59s - loss: 0.9217 - acc: 0.7313 - val_loss: 2.3656 - val_acc: 0.3333\n",
      "Epoch 4/5\n",
      "59s - loss: 0.8177 - acc: 0.7513 - val_loss: 2.0681 - val_acc: 0.4133\n",
      "Epoch 5/5\n",
      "59s - loss: 0.7236 - acc: 0.8087 - val_loss: 2.0871 - val_acc: 0.4187\n",
      "> zoom_range = 0.2\n",
      "Epoch 1/2\n",
      "81s - loss: 2.2627 - acc: 0.2440 - val_loss: 2.4695 - val_acc: 0.1920\n",
      "Epoch 2/2\n",
      "59s - loss: 1.6548 - acc: 0.4407 - val_loss: 2.4426 - val_acc: 0.2760\n",
      "Epoch 1/5\n",
      "59s - loss: 1.3403 - acc: 0.5687 - val_loss: 2.2419 - val_acc: 0.3173\n",
      "Epoch 2/5\n",
      "59s - loss: 1.1301 - acc: 0.6533 - val_loss: 2.2689 - val_acc: 0.3280\n",
      "Epoch 3/5\n",
      "59s - loss: 1.0219 - acc: 0.6860 - val_loss: 2.1976 - val_acc: 0.3640\n",
      "Epoch 4/5\n",
      "59s - loss: 0.9706 - acc: 0.7093 - val_loss: 2.1866 - val_acc: 0.3787\n",
      "Epoch 5/5\n",
      "59s - loss: 0.8870 - acc: 0.7387 - val_loss: 2.1181 - val_acc: 0.4067\n",
      "> zoom_range = 0.3\n",
      "Epoch 1/2\n",
      "82s - loss: 2.4285 - acc: 0.1833 - val_loss: 2.2162 - val_acc: 0.2507\n",
      "Epoch 2/2\n",
      "59s - loss: 1.8668 - acc: 0.3673 - val_loss: 2.0393 - val_acc: 0.3173\n",
      "Epoch 1/5\n",
      "59s - loss: 1.6400 - acc: 0.4480 - val_loss: 2.0754 - val_acc: 0.3333\n",
      "Epoch 2/5\n",
      "59s - loss: 1.5047 - acc: 0.5060 - val_loss: 2.1234 - val_acc: 0.3427\n",
      "Epoch 3/5\n",
      "59s - loss: 1.3627 - acc: 0.5533 - val_loss: 2.1447 - val_acc: 0.3547\n",
      "Epoch 4/5\n",
      "59s - loss: 1.2538 - acc: 0.5887 - val_loss: 2.3203 - val_acc: 0.3307\n",
      "Epoch 5/5\n",
      "59s - loss: 1.2130 - acc: 0.6227 - val_loss: 2.1474 - val_acc: 0.3587\n"
     ]
    }
   ],
   "source": [
    "# define the types of data augmentations we want to test, and the values we want to test for each\n",
    "aug_experiments = {\n",
    "    'rotation_range' : [0, 1, 3, 5, 10],\n",
    "    'width_shift_range': [0, 0.05, 1, 2, 4],\n",
    "    'height_shift_range': [0, 0.05, 1, 2, 4],\n",
    "    'shear_range': [0, 0.1, 0.15, 0.2, 0.3],\n",
    "    'zoom_range': [0, 0.1, 0.15, 0.2, 0.3],\n",
    "    'channel_shift_range': [0, 10, 20, 30, 50]\n",
    "}\n",
    "\n",
    "# used to store the results of data augmentation tests\n",
    "df_augs = pd.DataFrame(columns=['aug', 'aug_val', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "# try each type of data augmentation one at a time\n",
    "for k,v in aug_experiments.items():\n",
    "    # for each type, try 3-4 different levels of augmentation\n",
    "    for aug_val in v: \n",
    "        print('> {0} = {1}'.format(k, aug_val))\n",
    "        h = test_augmentation(**{k:aug_val})\n",
    "\n",
    "        # save the results of each tested value so that we can determine the best for\n",
    "        # each data augmentation type\n",
    "        df_augs = df_augs.append({\n",
    "            'aug': k, \n",
    "            'aug_val': aug_val,\n",
    "            'train_loss': np.mean(h.history['loss'][-3:]), \n",
    "            'train_acc': np.mean(h.history['acc'][-3:]), \n",
    "            'val_loss': np.mean(h.history['val_loss'][-3:]), \n",
    "            'val_acc': np.mean(h.history['val_acc'][-3:]) \n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_augs.to_csv(path+'data_augmentation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aug_val</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>channel_shift_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.392873</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>2.012688</td>\n",
       "      <td>0.413778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height_shift_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.403766</td>\n",
       "      <td>0.918444</td>\n",
       "      <td>1.865438</td>\n",
       "      <td>0.432889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotation_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.379833</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>1.768067</td>\n",
       "      <td>0.437778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shear_range</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.540318</td>\n",
       "      <td>0.870222</td>\n",
       "      <td>1.913431</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width_shift_range</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>0.752667</td>\n",
       "      <td>2.134572</td>\n",
       "      <td>0.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.372285</td>\n",
       "      <td>0.927111</td>\n",
       "      <td>2.034861</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aug_val  train_loss  train_acc  val_loss   val_acc\n",
       "aug                                                                    \n",
       "channel_shift_range     0.00    0.392873   0.926667  2.012688  0.413778\n",
       "height_shift_range      0.00    0.403766   0.918444  1.865438  0.432889\n",
       "rotation_range          0.00    0.379833   0.926000  1.768067  0.437778\n",
       "shear_range             0.10    0.540318   0.870222  1.913431  0.453333\n",
       "width_shift_range       0.05    0.853956   0.752667  2.134572  0.371111\n",
       "zoom_range              0.00    0.372285   0.927111  2.034861  0.420000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augs.sort_values('val_acc', ascending=False).groupby('aug').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(channel_shift_range=0.0, height_shift_range=0.0, rotation_range=0.0, \n",
    "                                   shear_range=0.10, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "aug_batches = gen_aug.flow(train_data, train_labels, batch_size=batch_size)\n",
    "epoch_steps = math.ceil(aug_batches.n/aug_batches.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "87s - loss: 2.2124 - acc: 0.2540 - val_loss: 2.4333 - val_acc: 0.2080\n",
      "Epoch 2/2\n",
      "60s - loss: 1.6187 - acc: 0.4480 - val_loss: 2.3062 - val_acc: 0.2853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d044ebcc50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_mem()\n",
    "model = simple_cnn()\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=2, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60s - loss: 1.3837 - acc: 0.5533 - val_loss: 2.2757 - val_acc: 0.3427\n",
      "Epoch 2/5\n",
      "60s - loss: 1.2061 - acc: 0.6260 - val_loss: 2.2440 - val_acc: 0.3920\n",
      "Epoch 3/5\n",
      "60s - loss: 1.0874 - acc: 0.6653 - val_loss: 1.9509 - val_acc: 0.4160\n",
      "Epoch 4/5\n",
      "60s - loss: 1.0007 - acc: 0.6980 - val_loss: 2.0170 - val_acc: 0.4293\n",
      "Epoch 5/5\n",
      "60s - loss: 0.9142 - acc: 0.7347 - val_loss: 2.0209 - val_acc: 0.4560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d045088e48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60s - loss: 0.8551 - acc: 0.7520 - val_loss: 1.9440 - val_acc: 0.4453\n",
      "Epoch 2/5\n",
      "60s - loss: 0.7815 - acc: 0.7673 - val_loss: 2.0283 - val_acc: 0.4000\n",
      "Epoch 3/5\n",
      "60s - loss: 0.7384 - acc: 0.7933 - val_loss: 1.9325 - val_acc: 0.4787\n",
      "Epoch 4/5\n",
      "59s - loss: 0.6885 - acc: 0.8120 - val_loss: 1.9163 - val_acc: 0.4813\n",
      "Epoch 5/5\n",
      "59s - loss: 0.6299 - acc: 0.8380 - val_loss: 1.9638 - val_acc: 0.4680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d045349fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models for Full Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex CONV Architecutre\n",
    "\n",
    "We are adding in regularization via Dropout so this will work better on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complex_cnn(p):\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = complex_cnn(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=2, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01\n",
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=5, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-compute output from various layers to use as input in various experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pre-compute output from VGG's 2nd to last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pop last layer and set model.outputs = to that of the now last layer\n",
    "model.layers.pop()\n",
    "\n",
    "# model.layers[-1].outbound_nodes = [] ... this is not needed\n",
    "model.outputs = [model.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(processed_data_path+'train_features_ft_2nd_to_ll.bc'):\n",
    "    train_features_ft = model.predict(train_data, 4)\n",
    "    val_features_ft = model.predict(val_data, 4)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_ft_2nd_to_ll.bc', train_features_ft)\n",
    "    save_array(processed_data_path+'val_features_ft_2nd_to_ll.bc', val_features_ft)\n",
    "else:\n",
    "    train_features_ft = load_array(processed_data_path+'train_features_ft_2nd_to_ll.bc')\n",
    "    val_features_ft = load_array(processed_data_path+'val_features_ft_2nd_to_ll.bc')\n",
    "    \n",
    "print(train_features_ft.shape)\n",
    "print(val_features_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pre-compute output from convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(processed_data_path+'train_features_ft_conv.bc'):\n",
    "    train_features_ft = model.predict(train_data, 4)\n",
    "    val_features_ft = model.predict(val_data, 4)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_ft_conv.bc', train_features_ft)\n",
    "    save_array(processed_data_path+'val_features_ft_conv.bc', val_features_ft)\n",
    "else:\n",
    "    train_features_ft = load_array(processed_data_path+'train_features_ft_conv.bc')\n",
    "    val_features_ft = load_array(processed_data_path+'val_features_ft_conv.bc')\n",
    "    \n",
    "print(train_features_ft.shape)\n",
    "print(val_features_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train a linear classifier using the pre-computed output from 2nd to last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "\n",
    "train_features_ft = load_array(processed_data_path+'train_features_ft_2nd_to_ll.bc')\n",
    "val_features_ft = load_array(processed_data_path+'val_features_ft_2nd_to_ll.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_lm_from_vgg_2ll():\n",
    "    m = Sequential([\n",
    "        Dense(10, activation='softmax', input_shape = model.layers[-1].output_shape[1:])\n",
    "    ])\n",
    "    \n",
    "    m.compile(optimizer=Adam(lr=1e-05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = build_lm_from_vgg_2ll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm.fit(train_features_ft, train_labels, batch_size=batch_size, epochs=12, shuffle=True,\n",
    "       validation_data=(val_features_ft, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Train model after replacing last layer with a Dense layer having 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = finetune(model, 10)\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
