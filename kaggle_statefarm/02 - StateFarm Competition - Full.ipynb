{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# adds parent directory to python path so we can access code located there\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path: sys.path.append(nb_dir)\n",
    "    \n",
    "# core imports\n",
    "from ohmeow_ml.keras_tf_util import *\n",
    "\n",
    "# other imports\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "    \n",
    "# configure autoreload to re-load changed modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define paths and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "DATA_HOME_DIR = current_dir + '/data/'\n",
    "DATA_CLASSES = [ dir for dir in os.listdir(DATA_HOME_DIR+'train') ]\n",
    "\n",
    "# path = DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR + 'sample/'\n",
    "sample_path = DATA_HOME_DIR + 'sample/'\n",
    "\n",
    "train_path = path + 'train/'\n",
    "val_path = path + 'valid/'\n",
    "test_path = path + 'test/'\n",
    "\n",
    "models_path = path + 'models/'                      # save weights here\n",
    "results_path = path + 'results/'                    # save predictions here\n",
    "processed_data_path = path + 'preprocesed_data/'    # save preprocessed data used for training here\n",
    "\n",
    "if not os.path.exists(models_path): os.makedirs(models_path)\n",
    "if not os.path.exists(results_path): os.makedirs(results_path)\n",
    "if not os.path.exists(processed_data_path): os.makedirs(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4 #64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx):\n",
    "    return np.clip(arr, (1-mx)/9, mx)\n",
    "\n",
    "def create_submission(preds, filename='subm.gz'):\n",
    "    subm = do_clip(preds, 0.93)\n",
    "    subm_file = results_path+filename\n",
    "    \n",
    "    batches = get_batches(train_path, batch_size=1, shuffle=False)\n",
    "    classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "    \n",
    "    df_subm = pd.DataFrame(subm, columns=classes)\n",
    "    df_subm.insert(0, 'img', [a[8:] for a in test_filenames])\n",
    "    #print(df_subm.head())\n",
    "    \n",
    "    df_subm.to_csv(subm_file, index=False, compression='gzip')\n",
    "    return subm_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We can save time by pre-processing the images (e.g., converting them to jpegs, resizing to 224x224) and saving them as a numpy array on the file system.  We can do the same for the train, validation, and test image class designations, filenames, and one-hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 750 images belonging to 10 classes.\n",
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get classes, one-hot encoded labels, and filenames\n",
    "train_classes, train_labels, train_filenames = get_batch_info(train_path)\n",
    "val_classes, val_labels, val_filenames = get_batch_info(val_path)\n",
    "test_filenames = get_batch_info(test_path)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data loaded ...\n",
      "validation data loaded ...\n"
     ]
    }
   ],
   "source": [
    " # get image data\n",
    "if not os.path.exists(processed_data_path+'train_data.bc'):\n",
    "    train_data = get_data(train_path)\n",
    "    save_array(processed_data_path+'train_data.bc', train_data)\n",
    "else:\n",
    "    train_data = load_array(processed_data_path+'train_data.bc')\n",
    "    print('training data loaded ...')\n",
    "\n",
    "if not os.path.exists(processed_data_path+'val_data.bc'):\n",
    "    val_data = get_data(val_path)\n",
    "    save_array(processed_data_path+'val_data.bc', val_data)\n",
    "else:\n",
    "    val_data = load_array(processed_data_path+'val_data.bc')\n",
    "    print('validation data loaded ...')\n",
    "\n",
    "# NOTE: with almost 80k records, trying to serialize the test set results in a memory error\n",
    "# if not os.path.exists(processed_data_path+'test_data.bc'):\n",
    "#     test_data = get_data(test_path)\n",
    "#     save_array(processed_data_path+'test_data.bc', test_data)\n",
    "# else:\n",
    "#     test_data = load_array(processed_data_path+'test_data.bc')\n",
    "#     print('test data loaded ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create training/validation batches and also define \"steps per epoch\" for each ... defines the # of batches per epoch (see `model.fit_generator()`).\n",
    "\n",
    "***ONLY RUN THIS CODE IF YOU NEED TO USE BATCHES INSTEAD OF PERSISTED IMAGE ARRAYS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# OPTION 1: BUILD BATCHES FROM FILE SYSTEM\n",
    "# train_batches = get_batches(train_path, batch_size=batch_size)\n",
    "# val_batches = get_batches(val_path, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# OPTION 2: BUILD BATCHES FROM IMAGE ARRAYS\n",
    "# gen = image.ImageDataGenerator()\n",
    "# train_batches = gen.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "# val_batches = gen.flow(val_data, val_labels, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# DEFINE # OF STEPS TO TAKE IN FITTING BATCHES FOR BOTH TRAINING AND VALIDATION EXAMPLES\n",
    "# epoch_steps = math.ceil(train_batches.n/train_batches.batch_size)\n",
    "# val_steps = math.ceil(val_batches.n/val_batches.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple CNN\n",
    "\n",
    "2 conv layers with max pooling + a simple dense network is a good simple CNN to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Without Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16951 samples, validate on 5473 samples\n",
      "Epoch 1/2\n",
      "578s - loss: 0.6795 - acc: 0.8251 - val_loss: 1.9279 - val_acc: 0.3967\n",
      "Epoch 2/2\n",
      "573s - loss: 0.1113 - acc: 0.9874 - val_loss: 1.8846 - val_acc: 0.4550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f088affb400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=2, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16951 samples, validate on 5473 samples\n",
      "Epoch 1/5\n",
      "574s - loss: 0.0513 - acc: 0.9965 - val_loss: 1.8822 - val_acc: 0.4679\n",
      "Epoch 2/5\n",
      "573s - loss: 0.0303 - acc: 0.9989 - val_loss: 1.8765 - val_acc: 0.4650\n",
      "Epoch 3/5\n",
      "574s - loss: 0.0196 - acc: 0.9998 - val_loss: 1.8850 - val_acc: 0.4688\n",
      "Epoch 4/5\n",
      "574s - loss: 0.0141 - acc: 0.9998 - val_loss: 1.8204 - val_acc: 0.4836\n",
      "Epoch 5/5\n",
      "573s - loss: 0.0105 - acc: 0.9999 - val_loss: 1.7986 - val_acc: 0.4931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f088af47e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=5, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(models_path+'simple_cnn_weights.h5') # val_acc = 0.4931"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aug_val</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>channel_shift_range</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.464624</td>\n",
       "      <td>0.902444</td>\n",
       "      <td>1.735638</td>\n",
       "      <td>0.464444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height_shift_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.431795</td>\n",
       "      <td>0.917333</td>\n",
       "      <td>1.985304</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotation_range</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.817478</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>1.790981</td>\n",
       "      <td>0.476444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shear_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.431570</td>\n",
       "      <td>0.912667</td>\n",
       "      <td>1.761170</td>\n",
       "      <td>0.480444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width_shift_range</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.867643</td>\n",
       "      <td>0.755333</td>\n",
       "      <td>1.771413</td>\n",
       "      <td>0.515556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.445235</td>\n",
       "      <td>0.899778</td>\n",
       "      <td>1.787687</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aug_val  train_loss  train_acc  val_loss   val_acc\n",
       "aug                                                                    \n",
       "channel_shift_range    10.00    0.464624   0.902444  1.735638  0.464444\n",
       "height_shift_range      0.00    0.431795   0.917333  1.985304  0.436000\n",
       "rotation_range         10.00    0.817478   0.770444  1.790981  0.476444\n",
       "shear_range             0.00    0.431570   0.912667  1.761170  0.480444\n",
       "width_shift_range       0.05    0.867643   0.755333  1.771413  0.515556\n",
       "zoom_range              0.00    0.445235   0.899778  1.787687  0.477778"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best values\n",
    "df_augs = pd.read_csv(sample_path+'data_augmentation_results.csv')\n",
    "df_augs.sort_values('val_acc', ascending=False).groupby('aug').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(channel_shift_range=10.0, height_shift_range=0.0, rotation_range=10.0, \n",
    "                                   shear_range=0.0, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "aug_batches = gen_aug.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "577s - loss: 1.4254 - acc: 0.5438 - val_loss: 1.8220 - val_acc: 0.3768\n",
      "Epoch 2/2\n",
      "575s - loss: 0.5995 - acc: 0.8449 - val_loss: 1.7175 - val_acc: 0.4952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08731d8630>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_steps = math.ceil(aug_batches.n/aug_batches.batch_size)\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=2, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "575s - loss: 0.3676 - acc: 0.9169 - val_loss: 1.6963 - val_acc: 0.5085\n",
      "Epoch 2/4\n",
      "574s - loss: 0.2698 - acc: 0.9427 - val_loss: 1.6049 - val_acc: 0.5363\n",
      "Epoch 3/4\n",
      "574s - loss: 0.2061 - acc: 0.9589 - val_loss: 1.5723 - val_acc: 0.5461\n",
      "Epoch 4/4\n",
      "575s - loss: 0.1687 - acc: 0.9680 - val_loss: 1.5861 - val_acc: 0.5407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08731d85f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=4, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "577s - loss: 0.0623 - acc: 0.9901 - val_loss: 1.5507 - val_acc: 0.5620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08722f2668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=4, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(models_path+'simple_cnn_da_weights.h5') # val_acc = 0.5620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Complex CNN Architecutre\n",
    "\n",
    "We are adding in regularization via Dropout so this will work better on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def complex_cnn(p_do=0.5, n_dense_outputs=256):\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(n_dense_outputs, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p_do/4),\n",
    "        Dense(n_dense_outputs, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p_do),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = complex_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(channel_shift_range=10.0, height_shift_range=0.0, rotation_range=10.0, \n",
    "                                   shear_range=0.0, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "aug_batches = gen_aug.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "epoch_steps = math.ceil(aug_batches.n/aug_batches.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "636s - loss: 1.7451 - acc: 0.4699 - val_loss: 2.1765 - val_acc: 0.3170\n",
      "Epoch 2/2\n",
      "634s - loss: 0.6807 - acc: 0.7763 - val_loss: 1.7729 - val_acc: 0.5081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0858ba55f8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(aug_batches, epoch_steps, epochs=2, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "633s - loss: 0.4139 - acc: 0.8669 - val_loss: 1.6830 - val_acc: 0.5695\n",
      "Epoch 2/4\n",
      "634s - loss: 0.2573 - acc: 0.9206 - val_loss: 1.4854 - val_acc: 0.6141\n",
      "Epoch 3/4\n",
      "633s - loss: 0.1832 - acc: 0.9451 - val_loss: 1.4465 - val_acc: 0.6386\n",
      "Epoch 4/4\n",
      "634s - loss: 0.1550 - acc: 0.9540 - val_loss: 1.6164 - val_acc: 0.5752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f083394be10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=4, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "633s - loss: 0.0887 - acc: 0.9746 - val_loss: 1.6451 - val_acc: 0.6464\n",
      "Epoch 2/4\n",
      "632s - loss: 0.0756 - acc: 0.9782 - val_loss: 1.5715 - val_acc: 0.6521\n",
      "Epoch 3/4\n",
      "632s - loss: 0.0657 - acc: 0.9810 - val_loss: 1.7755 - val_acc: 0.6168\n",
      "Epoch 4/4\n",
      "633s - loss: 0.0628 - acc: 0.9809 - val_loss: 1.7813 - val_acc: 0.6366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f083395d978>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=6, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "633s - loss: 0.0380 - acc: 0.9887 - val_loss: 1.7406 - val_acc: 0.5978\n",
      "Epoch 2/4\n",
      "633s - loss: 0.0387 - acc: 0.9887 - val_loss: 1.5417 - val_acc: 0.6592\n",
      "Epoch 3/4\n",
      "633s - loss: 0.0309 - acc: 0.9906 - val_loss: 1.8036 - val_acc: 0.6338\n",
      "Epoch 4/4\n",
      "631s - loss: 0.0340 - acc: 0.9906 - val_loss: 1.8142 - val_acc: 0.6203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f083395dc88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.00001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=8, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(models_path+'complex_cnn_da_weights.h5') # val_acc = ~0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train a linear classifier using the pre-computed output from 2nd to last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pop last layer and set model.outputs = to that of the now last layer\n",
    "model.layers.pop()\n",
    "\n",
    "# model.layers[-1].outbound_nodes = [] ... this is not needed\n",
    "model.outputs = [model.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Pre-compute output for train, validation, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (1500, 4096)\n",
      "validation data: (750, 4096)\n",
      "augmented data: (7500, 4096)\n",
      "test data: (500, 4096)\n"
     ]
    }
   ],
   "source": [
    "# A. precompute the 2nd to last layer for training and validation data sets\n",
    "if not os.path.exists(processed_data_path+'train_features_ll.bc'):\n",
    "    train_features_ll = model.predict(train_data, 4)\n",
    "    val_features_ll = model.predict(val_data, 4)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_ll.bc', train_features_ll)\n",
    "    save_array(processed_data_path+'val_features_ll.bc', val_features_ll)\n",
    "else:\n",
    "    train_features_ll = load_array(processed_data_path+'train_features_ll.bc')\n",
    "    val_features_ll = load_array(processed_data_path+'val_features_ll.bc')\n",
    "    \n",
    "print('training data:', train_features_ll.shape)\n",
    "print('validation data:', val_features_ll.shape)\n",
    "\n",
    "# B. do the same for augmented training data ... make this 5-10x larger\n",
    "if not os.path.exists(processed_data_path+'da_train_features_ll.bc'):\n",
    "    da_gen = image.ImageDataGenerator(channel_shift_range=10.0, height_shift_range=0.0, rotation_range=10.0, \n",
    "                                   shear_range=0.0, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "    # shuffle=False because we are going to have to add labels later for however many \n",
    "    # augmented sets of the training data\n",
    "    da_batches = get_batches(train_path, da_gen, batch_size=batch_size, shuffle=False) \n",
    "    da_train_features_ll = np.concatenate(\n",
    "        [ model.predict_generator(da_batches, (da_batches.n/batch_size), verbose=2) for i in range(5)])\n",
    "    \n",
    "    save_array(processed_data_path+'da_train_features_ll.bc', da_train_features_ll)\n",
    "else:\n",
    "    da_train_features_ll = load_array(processed_data_path+'da_train_features_ll.bc')\n",
    "    \n",
    "print('augmented data:', da_train_features_ll.shape)\n",
    "\n",
    "# C. do the same for test data\n",
    "if not os.path.exists(processed_data_path+'test_features_ll.bc'):\n",
    "    test_batches = get_batches(test_path, batch_size=batch_size, shuffle=False)\n",
    "    test_features_ll = model.predict_generator(test_batches, (test_batches.n/batch_size), verbose=2)\n",
    "    save_array(processed_data_path+'test_features_ll.bc', test_features_ll)\n",
    "else:\n",
    "    test_features_ll = load_array(processed_data_path+'test_features_ll.bc')\n",
    "    \n",
    "print('test data:', test_features_ll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all training features shape: (9000, 4096)\n",
      "all training labels shape: (9000, 10)\n"
     ]
    }
   ],
   "source": [
    "all_train_features_ll = np.concatenate([da_train_features_ll, train_features_ll])\n",
    "all_train_labels_ll = np.concatenate([train_labels]*6)\n",
    "\n",
    "print('all training features shape:', all_train_features_ll.shape)\n",
    "print('all training labels shape:', all_train_labels_ll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable = False\n",
    "ft_ll_model = Sequential([ Dense(10, activation='softmax', input_shape=model.layers[-1].output_shape[1:]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "8s - loss: 2.5488 - acc: 0.1506 - val_loss: 2.5022 - val_acc: 0.1587\n",
      "Epoch 2/5\n",
      "8s - loss: 2.1464 - acc: 0.2343 - val_loss: 2.3253 - val_acc: 0.1907\n",
      "Epoch 3/5\n",
      "8s - loss: 1.9491 - acc: 0.2921 - val_loss: 2.2579 - val_acc: 0.2320\n",
      "Epoch 4/5\n",
      "8s - loss: 1.8190 - acc: 0.3374 - val_loss: 2.1852 - val_acc: 0.2333\n",
      "Epoch 5/5\n",
      "8s - loss: 1.7207 - acc: 0.3658 - val_loss: 2.1545 - val_acc: 0.2627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fe177f7f0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_ll_model.compile(optimizer=Adam(lr=1e-05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "ft_ll_model.fit(all_train_features_ll, all_train_labels_ll, batch_size=batch_size, epochs=5, \n",
    "          validation_data=(val_features_ll, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "8s - loss: 1.6441 - acc: 0.3917 - val_loss: 2.1306 - val_acc: 0.2787\n",
      "Epoch 2/5\n",
      "8s - loss: 1.5805 - acc: 0.4150 - val_loss: 2.1393 - val_acc: 0.2773\n",
      "Epoch 3/5\n",
      "8s - loss: 1.5275 - acc: 0.4347 - val_loss: 2.0904 - val_acc: 0.2800\n",
      "Epoch 4/5\n",
      "8s - loss: 1.4796 - acc: 0.4434 - val_loss: 2.0754 - val_acc: 0.2813\n",
      "Epoch 5/5\n",
      "8s - loss: 1.4391 - acc: 0.4631 - val_loss: 2.1100 - val_acc: 0.2827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fe29950b8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_ll_model.optimizer.lr = 0.01\n",
    "ft_ll_model.fit(all_train_features_ll, all_train_labels_ll, batch_size=batch_size, epochs=5, \n",
    "          validation_data=(val_features_ll, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (Unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-1a6a67e934d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mft_ll_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ft_ll_model_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# val_acc = ???\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1474482825505\\work\\h5py\\_objects.c:2705)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1474482825505\\work\\h5py\\_objects.c:2663)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create (C:\\Minonda\\conda-bld\\h5py_1474482825505\\work\\h5py\\h5f.c:2118)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (Unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "ft_ll_model.save_weights(models_path+'ft_ll_model_weights.h5') # val_acc = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Precompute the convolutional and use in FC NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(include_top=False, weights='imagenet', input_shape=(224,224,3)) # must include input_shape if include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Precompute output for train, validation, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (1500, 7, 7, 512)\n",
      "validation data: (750, 7, 7, 512)\n",
      "augmented data: (7500, 7, 7, 512)\n",
      "test data: (500, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "# A. precompute the 2nd to last layer for training and validation data sets\n",
    "if not os.path.exists(processed_data_path+'train_features_conv.bc'):\n",
    "    train_features_conv = model.predict(train_data, 4)\n",
    "    val_features_conv = model.predict(val_data, 4)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_conv.bc', train_features_conv)\n",
    "    save_array(processed_data_path+'val_features_conv.bc', val_features_conv)\n",
    "else:\n",
    "    train_features_conv = load_array(processed_data_path+'train_features_conv.bc')\n",
    "    val_features_conv = load_array(processed_data_path+'val_features_conv.bc')\n",
    "    \n",
    "print('training data:', train_features_conv.shape)\n",
    "print('validation data:', val_features_conv.shape)\n",
    "\n",
    "# B. do the same for augmented training data ... make this 5-10x larger\n",
    "if not os.path.exists(processed_data_path+'da_train_features_conv.bc'):\n",
    "    da_gen = image.ImageDataGenerator(channel_shift_range=10.0, height_shift_range=0.0, rotation_range=10.0, \n",
    "                                   shear_range=0.0, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "    # shuffle=False because we are going to have to add labels later for however many \n",
    "    # augmented sets of the training data\n",
    "    da_batches_conv = get_batches(train_path, da_gen, batch_size=batch_size, shuffle=False) \n",
    "    da_train_features_conv = np.concatenate(\n",
    "        [ model.predict_generator(da_batches_conv, (da_batches_conv.n/batch_size), verbose=2) for i in range(5) ])\n",
    "    \n",
    "    save_array(processed_data_path+'da_train_features_conv.bc', da_train_features_conv)\n",
    "else:\n",
    "    da_train_features_conv = load_array(processed_data_path+'da_train_features_conv.bc')\n",
    "    \n",
    "print('augmented data:', da_train_features_conv.shape)\n",
    "\n",
    "# C. do the same for test data\n",
    "if not os.path.exists(processed_data_path+'test_features_conv.bc'):\n",
    "    test_batches_conv = get_batches(test_path, batch_size=batch_size, shuffle=False)\n",
    "    test_features_conv = model.predict_generator(test_batches_conv, (test_batches_conv.n/batch_size), verbose=2)\n",
    "    save_array(processed_data_path+'test_features_conv.bc', test_features_conv)\n",
    "else:\n",
    "    test_features_conv = load_array(processed_data_path+'test_features_conv.bc')\n",
    "    \n",
    "print('test data:', test_features_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all training features shape: (9000, 7, 7, 512)\n",
      "all training labels shape: (9000, 10)\n"
     ]
    }
   ],
   "source": [
    "all_train_features_conv = np.concatenate([da_train_features_conv, train_features_conv])\n",
    "all_train_labels_conv = np.concatenate([train_labels]*6)\n",
    "\n",
    "print('all training features shape:', all_train_features_conv.shape)\n",
    "print('all training labels shape:', all_train_labels_conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_fc_layers(dropout_p=0.5, dense_output=256):\n",
    "    return [\n",
    "        Flatten(input_shape=model.layers[-1].output_shape[1:]),\n",
    "        Dropout(dropout_p),\n",
    "        Dense(dense_output, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_p),\n",
    "        Dense(dense_output, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_p),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model = Sequential(build_fc_layers())\n",
    "fc_model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 750 samples\n",
      "Epoch 1/1\n",
      "66s - loss: 2.3326 - acc: 0.2373 - val_loss: 1.5670 - val_acc: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f2d196f28>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(all_train_features_conv, all_train_labels_conv, batch_size=batch_size, epochs=1,\n",
    "            validation_data=(val_features_conv, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 750 samples\n",
      "Epoch 1/4\n",
      "64s - loss: 1.3589 - acc: 0.4618 - val_loss: 1.3327 - val_acc: 0.5120\n",
      "Epoch 2/4\n",
      "65s - loss: 1.3067 - acc: 0.4729 - val_loss: 1.3173 - val_acc: 0.5160\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-f553588b1a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fc_model.fit(all_train_features_conv, all_train_labels_conv, batch_size=batch_size, epochs=4,\n\u001b[0;32m----> 3\u001b[0;31m             validation_data=(val_features_conv, val_labels), verbose=2)\n\u001b[0m",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fc_model.optimizer.lr = 0.01\n",
    "fc_model.fit(all_train_features_conv, all_train_labels_conv, batch_size=batch_size, epochs=4,\n",
    "            validation_data=(val_features_conv, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 750 samples\n",
      "Epoch 1/4\n",
      "64s - loss: 1.2683 - acc: 0.4803 - val_loss: 1.2923 - val_acc: 0.5880\n",
      "Epoch 2/4\n",
      "64s - loss: 1.2478 - acc: 0.4963 - val_loss: 1.4411 - val_acc: 0.5040\n",
      "Epoch 3/4\n",
      "64s - loss: 1.2132 - acc: 0.5012 - val_loss: 1.1812 - val_acc: 0.5933\n",
      "Epoch 4/4\n",
      "64s - loss: 1.1951 - acc: 0.5171 - val_loss: 1.3182 - val_acc: 0.5053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f2d1ee3c8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.optimizer.lr = 0.001\n",
    "fc_model.fit(all_train_features_conv, all_train_labels_conv, batch_size=batch_size, epochs=4,\n",
    "            validation_data=(val_features_conv, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 750 samples\n",
      "Epoch 1/4\n",
      "64s - loss: 1.1709 - acc: 0.5247 - val_loss: 1.3111 - val_acc: 0.5000\n",
      "Epoch 2/4\n",
      "64s - loss: 1.1642 - acc: 0.5229 - val_loss: 1.3094 - val_acc: 0.4840\n",
      "Epoch 3/4\n",
      "65s - loss: 1.1435 - acc: 0.5334 - val_loss: 1.3587 - val_acc: 0.4840\n",
      "Epoch 4/4\n",
      "65s - loss: 1.1268 - acc: 0.5342 - val_loss: 1.3018 - val_acc: 0.5293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f2d1ee198>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.optimizer.lr = 0.0001\n",
    "fc_model.fit(all_train_features_conv, all_train_labels_conv, batch_size=batch_size, epochs=4,\n",
    "            validation_data=(val_features_conv, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(models_path+'ft_fc_model_weights.h5') # val_acc = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Evaluate and create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fc_model.evaluate(val_features_conv, val_labels, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = fc_model.predict(test_features_conv, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='C:\\Development\\_training\\machine_learning\\ml-fastai-tensorflow\\kaggle_statefarm/data/sample/results/ft_fc_model_subm01.gz' target='_blank'>C:\\Development\\_training\\machine_learning\\ml-fastai-tensorflow\\kaggle_statefarm/data/sample/results/ft_fc_model_subm01.gz</a><br>"
      ],
      "text/plain": [
       "C:\\Development\\_training\\machine_learning\\ml-fastai-tensorflow\\kaggle_statefarm\\data\\sample\\results\\ft_fc_model_subm01.gz"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_file = create_submission(preds, 'ft_fc_model_subm01.gz')\n",
    "FileLink(subm_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
