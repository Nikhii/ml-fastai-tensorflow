{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# adds parent directory to python path so we can access code located there\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path: sys.path.append(nb_dir)\n",
    "    \n",
    "# core imports\n",
    "from ohmeow_ml.keras_tf_util import *\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "    \n",
    "# configure autoreload to re-load changed modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define paths and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "DATA_HOME_DIR = current_dir + '/data/'\n",
    "DATA_CLASSES = [ dir for dir in os.listdir(DATA_HOME_DIR+'train') ]\n",
    "\n",
    "# path = DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR + 'sample/'\n",
    "sample_path = DATA_HOME_DIR + 'sample/'\n",
    "\n",
    "train_path = path + 'train/'\n",
    "val_path = path + 'valid/'\n",
    "test_path = path + 'test/'\n",
    "\n",
    "models_path = path + 'models/'                      # save weights here\n",
    "results_path = path + 'results/'                    # save predictions here\n",
    "processed_data_path = path + 'preprocesed_data/'    # save preprocessed data used for training here\n",
    "\n",
    "if not os.path.exists(models_path): os.makedirs(models_path)\n",
    "if not os.path.exists(results_path): os.makedirs(results_path)\n",
    "if not os.path.exists(processed_data_path): os.makedirs(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4 #64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We can save time by pre-processing the images (e.g., converting them to jpegs, resizing to 224x224) and saving them as a numpy array on the file system.  We can do the same for the train, validation, and test image class designations, filenames, and one-hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 750 images belonging to 10 classes.\n",
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get classes, one-hot encoded labels, and filenames\n",
    "train_classes, train_labels, train_filenames = get_batch_info(train_path)\n",
    "val_classes, val_labels, val_filenames = get_batch_info(val_path)\n",
    "test_filenames = get_batch_info(test_path)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data loaded ...\n",
      "validation data loaded ...\n",
      "test data loaded ...\n"
     ]
    }
   ],
   "source": [
    " # get image data\n",
    "if not os.path.exists(processed_data_path+'train_data.bc'):\n",
    "    train_data = get_data(train_path)\n",
    "    save_array(processed_data_path+'train_data.bc', train_data)\n",
    "else:\n",
    "    train_data = load_array(processed_data_path+'train_data.bc')\n",
    "    print('training data loaded ...')\n",
    "\n",
    "if not os.path.exists(processed_data_path+'val_data.bc'):\n",
    "    val_data = get_data(val_path)\n",
    "    save_array(processed_data_path+'val_data.bc', val_data)\n",
    "else:\n",
    "    val_data = load_array(processed_data_path+'val_data.bc')\n",
    "    print('validation data loaded ...')\n",
    "\n",
    "if not os.path.exists(processed_data_path+'test_data.bc'):\n",
    "    test_data = get_data(test_path)\n",
    "    save_array(processed_data_path+'test_data.bc', test_data)\n",
    "else:\n",
    "    test_data = load_array(processed_data_path+'test_data.bc')\n",
    "    print('test data loaded ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create training/validation batches and also define \"steps per epoch\" for each ... defines the # of batches per epoch (see `model.fit_generator()`).\n",
    "\n",
    "***ONLY RUN THIS CODE IF YOU NEED TO USE BATCHES INSTEAD OF PERSISTED IMAGE ARRAYS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# OPTION 1: BUILD BATCHES FROM FILE SYSTEM\n",
    "# train_batches = get_batches(train_path, batch_size=batch_size)\n",
    "# val_batches = get_batches(val_path, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# OPTION 2: BUILD BATCHES FROM IMAGE ARRAYS\n",
    "# gen = image.ImageDataGenerator()\n",
    "# train_batches = gen.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "# val_batches = gen.flow(val_data, val_labels, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# DEFINE # OF STEPS TO TAKE IN FITTING BATCHES FOR BOTH TRAINING AND VALIDATION EXAMPLES\n",
    "# epoch_steps = math.ceil(train_batches.n/train_batches.batch_size)\n",
    "# val_steps = math.ceil(val_batches.n/val_batches.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN\n",
    "\n",
    "2 conv layers with max pooling + a simple dense network is a good simple CNN to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 750 samples\n",
      "Epoch 1/2\n",
      "61s - loss: 1.9962 - acc: 0.3373 - val_loss: 2.3012 - val_acc: 0.2800\n",
      "Epoch 2/2\n",
      "59s - loss: 1.1325 - acc: 0.6647 - val_loss: 2.5793 - val_acc: 0.2627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ead3b81e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=2, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "59s - loss: 0.7972 - acc: 0.8013 - val_loss: 2.0110 - val_acc: 0.3547\n",
      "Epoch 2/5\n",
      "59s - loss: 0.5998 - acc: 0.8620 - val_loss: 2.0129 - val_acc: 0.3907\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4617 - acc: 0.9140 - val_loss: 1.8635 - val_acc: 0.4227\n",
      "Epoch 4/5\n",
      "59s - loss: 0.4065 - acc: 0.9187 - val_loss: 1.9141 - val_acc: 0.4013\n",
      "Epoch 5/5\n",
      "59s - loss: 0.3253 - acc: 0.9407 - val_loss: 2.0225 - val_acc: 0.4027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ead3bac208>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit(train_data, train_labels, batch_size=batch_size, epochs=5, shuffle=True, \n",
    "          validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aug_val</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>channel_shift_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.392873</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>2.012688</td>\n",
       "      <td>0.413778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height_shift_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.403766</td>\n",
       "      <td>0.918444</td>\n",
       "      <td>1.865438</td>\n",
       "      <td>0.432889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotation_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.379833</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>1.768067</td>\n",
       "      <td>0.437778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shear_range</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.540318</td>\n",
       "      <td>0.870222</td>\n",
       "      <td>1.913431</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width_shift_range</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>0.752667</td>\n",
       "      <td>2.134572</td>\n",
       "      <td>0.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom_range</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.372285</td>\n",
       "      <td>0.927111</td>\n",
       "      <td>2.034861</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aug_val  train_loss  train_acc  val_loss   val_acc\n",
       "aug                                                                    \n",
       "channel_shift_range     0.00    0.392873   0.926667  2.012688  0.413778\n",
       "height_shift_range      0.00    0.403766   0.918444  1.865438  0.432889\n",
       "rotation_range          0.00    0.379833   0.926000  1.768067  0.437778\n",
       "shear_range             0.10    0.540318   0.870222  1.913431  0.453333\n",
       "width_shift_range       0.05    0.853956   0.752667  2.134572  0.371111\n",
       "zoom_range              0.00    0.372285   0.927111  2.034861  0.420000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best values\n",
    "df_augs = pd.read_csv(sample_path+'data_augmentation_results.csv')\n",
    "df_augs.sort_values('val_acc', ascending=False).groupby('aug').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(channel_shift_range=0.0, height_shift_range=0.0, rotation_range=0.0, \n",
    "                                   shear_range=0.10, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "aug_batches = gen_aug.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = simple_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60s - loss: 2.2428 - acc: 0.2433 - val_loss: 2.4668 - val_acc: 0.1587\n",
      "Epoch 2/2\n",
      "59s - loss: 1.6098 - acc: 0.4487 - val_loss: 2.2202 - val_acc: 0.3160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eaf68fef60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_steps = math.ceil(aug_batches.n/aug_batches.batch_size)\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=2, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "59s - loss: 1.3402 - acc: 0.5620 - val_loss: 2.1860 - val_acc: 0.3480\n",
      "Epoch 2/4\n",
      "59s - loss: 1.1932 - acc: 0.6207 - val_loss: 2.1291 - val_acc: 0.3587\n",
      "Epoch 3/4\n",
      "59s - loss: 1.0703 - acc: 0.6740 - val_loss: 2.1869 - val_acc: 0.3413\n",
      "Epoch 4/4\n",
      "59s - loss: 0.9866 - acc: 0.6987 - val_loss: 1.9671 - val_acc: 0.4467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ead3f856d8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=4, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "59s - loss: 0.8422 - acc: 0.7500 - val_loss: 1.9100 - val_acc: 0.4267\n",
      "Epoch 2/15\n",
      "59s - loss: 0.8300 - acc: 0.7587 - val_loss: 1.9486 - val_acc: 0.4080\n",
      "Epoch 3/15\n",
      "59s - loss: 0.7511 - acc: 0.7793 - val_loss: 1.8466 - val_acc: 0.4453\n",
      "Epoch 4/15\n",
      "59s - loss: 0.7145 - acc: 0.7960 - val_loss: 1.8369 - val_acc: 0.4627\n",
      "Epoch 5/15\n",
      "59s - loss: 0.6332 - acc: 0.8220 - val_loss: 1.9578 - val_acc: 0.4467\n",
      "Epoch 6/15\n",
      "59s - loss: 0.6237 - acc: 0.8280 - val_loss: 2.0271 - val_acc: 0.4213\n",
      "Epoch 7/15\n",
      "59s - loss: 0.6231 - acc: 0.8187 - val_loss: 1.9597 - val_acc: 0.4613\n",
      "Epoch 8/15\n",
      "59s - loss: 0.5779 - acc: 0.8467 - val_loss: 1.9437 - val_acc: 0.4400\n",
      "Epoch 9/15\n",
      "59s - loss: 0.5020 - acc: 0.8527 - val_loss: 2.0274 - val_acc: 0.4373\n",
      "Epoch 10/15\n",
      "59s - loss: 0.5151 - acc: 0.8607 - val_loss: 2.0055 - val_acc: 0.4707\n",
      "Epoch 11/15\n",
      "59s - loss: 0.4504 - acc: 0.8800 - val_loss: 2.0425 - val_acc: 0.4813\n",
      "Epoch 12/15\n",
      "59s - loss: 0.4357 - acc: 0.8840 - val_loss: 1.9533 - val_acc: 0.4947\n",
      "Epoch 13/15\n",
      "59s - loss: 0.4213 - acc: 0.8913 - val_loss: 1.9934 - val_acc: 0.4800\n",
      "Epoch 14/15\n",
      "59s - loss: 0.4570 - acc: 0.8813 - val_loss: 1.8499 - val_acc: 0.5107\n",
      "Epoch 15/15\n",
      "59s - loss: 0.3907 - acc: 0.9087 - val_loss: 1.8914 - val_acc: 0.5013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eaf92a7cf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=15, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex CNN Architecutre\n",
    "\n",
    "We are adding in regularization via Dropout so this will work better on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complex_cnn(p_do=0.5, n_dense_outputs=256):\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224,224,3)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(n_dense_outputs, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p_do/2),\n",
    "        Dense(n_dense_outputs, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p_do),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = complex_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(channel_shift_range=0.0, height_shift_range=0.0, rotation_range=0.0, \n",
    "                                   shear_range=0.10, width_shift_range=0.05, zoom_range=0.0)\n",
    "\n",
    "aug_batches = gen_aug.flow(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "epoch_steps = math.ceil(aug_batches.n/aug_batches.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "59s - loss: 3.1382 - acc: 0.1027 - val_loss: 3.1901 - val_acc: 0.1200\n",
      "Epoch 2/2\n",
      "55s - loss: 2.9258 - acc: 0.1433 - val_loss: 3.3729 - val_acc: 0.1493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb019dcac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(aug_batches, epoch_steps, epochs=2, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "56s - loss: 2.7414 - acc: 0.1533 - val_loss: 3.3178 - val_acc: 0.1520\n",
      "Epoch 2/5\n",
      "55s - loss: 2.6023 - acc: 0.1793 - val_loss: 3.0626 - val_acc: 0.1787\n",
      "Epoch 3/5\n",
      "55s - loss: 2.4840 - acc: 0.1973 - val_loss: 2.7957 - val_acc: 0.1720\n",
      "Epoch 4/5\n",
      "55s - loss: 2.4386 - acc: 0.2047 - val_loss: 2.7143 - val_acc: 0.1773\n",
      "Epoch 5/5\n",
      "55s - loss: 2.4602 - acc: 0.2087 - val_loss: 2.6656 - val_acc: 0.1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb01ed9eb8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=5, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56s - loss: 2.3549 - acc: 0.2387 - val_loss: 2.5904 - val_acc: 0.2080\n",
      "Epoch 2/10\n",
      "55s - loss: 2.2514 - acc: 0.2540 - val_loss: 2.6188 - val_acc: 0.2147\n",
      "Epoch 3/10\n",
      "55s - loss: 2.1452 - acc: 0.2940 - val_loss: 2.6114 - val_acc: 0.2187\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f68e1fcb6812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Development\\_tools\\Anaconda3\\envs\\ml_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.00001\n",
    "model.fit_generator(aug_batches, epoch_steps, epochs=10, validation_data=(val_data, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-compute output from various layers to use as input in various experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pre-compute output from VGG's 2nd to last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pop last layer and set model.outputs = to that of the now last layer\n",
    "model.layers.pop()\n",
    "\n",
    "# model.layers[-1].outbound_nodes = [] ... this is not needed\n",
    "model.outputs = [model.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(processed_data_path+'train_features_ft_2nd_to_ll.bc'):\n",
    "    train_features_ft = model.predict(train_data, 4)\n",
    "    val_features_ft = model.predict(val_data, 4)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_ft_2nd_to_ll.bc', train_features_ft)\n",
    "    save_array(processed_data_path+'val_features_ft_2nd_to_ll.bc', val_features_ft)\n",
    "else:\n",
    "    train_features_ft = load_array(processed_data_path+'train_features_ft_2nd_to_ll.bc')\n",
    "    val_features_ft = load_array(processed_data_path+'val_features_ft_2nd_to_ll.bc')\n",
    "    \n",
    "print(train_features_ft.shape)\n",
    "print(val_features_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pre-compute output from convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(processed_data_path+'train_features_ft_conv.bc'):\n",
    "    train_features_ft = model.predict(train_data, 4)\n",
    "    val_features_ft = model.predict(val_data, 4)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_ft_conv.bc', train_features_ft)\n",
    "    save_array(processed_data_path+'val_features_ft_conv.bc', val_features_ft)\n",
    "else:\n",
    "    train_features_ft = load_array(processed_data_path+'train_features_ft_conv.bc')\n",
    "    val_features_ft = load_array(processed_data_path+'val_features_ft_conv.bc')\n",
    "    \n",
    "print(train_features_ft.shape)\n",
    "print(val_features_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train a linear classifier using the pre-computed output from 2nd to last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "\n",
    "train_features_ft = load_array(processed_data_path+'train_features_ft_2nd_to_ll.bc')\n",
    "val_features_ft = load_array(processed_data_path+'val_features_ft_2nd_to_ll.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_lm_from_vgg_2ll():\n",
    "    m = Sequential([\n",
    "        Dense(10, activation='softmax', input_shape = model.layers[-1].output_shape[1:])\n",
    "    ])\n",
    "    \n",
    "    m.compile(optimizer=Adam(lr=1e-05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = build_lm_from_vgg_2ll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm.fit(train_features_ft, train_labels, batch_size=batch_size, epochs=12, shuffle=True,\n",
    "       validation_data=(val_features_ft, val_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Train model after replacing last layer with a Dense layer having 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = finetune(model, 10)\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
