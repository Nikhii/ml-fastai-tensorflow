{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# adds parent directory to python path so we can access code located there\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path: sys.path.append(nb_dir)\n",
    "    \n",
    "# core imports\n",
    "from ohmeow_ml.keras_tf_util import *\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "    \n",
    "# configure autoreload to re-load changed modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define paths and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "DATA_HOME_DIR = current_dir + '/data/'\n",
    "DATA_CLASSES = [ dir for dir in os.listdir(DATA_HOME_DIR+'train') ]\n",
    "\n",
    "# path = DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR + 'sample/'\n",
    "\n",
    "train_path = path + 'train/'\n",
    "val_path = path + 'valid/'\n",
    "test_path = DATA_HOME_DIR + 'test/'\n",
    "\n",
    "models_path = path + 'models/'                      # save weights here\n",
    "results_path = path + 'results/'                    # save predictions here\n",
    "processed_data_path = path + 'preprocesed_data/'    # save preprocessed data used for training here\n",
    "\n",
    "if not os.path.exists(models_path): os.makedirs(models_path)\n",
    "if not os.path.exists(results_path): os.makedirs(results_path)\n",
    "if not os.path.exists(processed_data_path): os.makedirs(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4 #64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We can save time by pre-processing the images (e.g., converting them to jpegs, resizing to 224x224) and saving them as a numpy array on the file system.  We can do the same for the train, validation, and test image class designations, filenames, and one-hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 300 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get classes, one-hot encoded labels, and filenames\n",
    "train_classes, train_labels, train_filenames = get_batch_info(train_path)\n",
    "val_classes, val_labels, val_filenames = get_batch_info(val_path)\n",
    "test_filenames = get_batch_info(test_path)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 300 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get image data\n",
    "if not os.path.exists(processed_data_path+'train_data.bc'):\n",
    "    train_data = get_data(train_path)\n",
    "    save_array(processed_data_path+'train_data.bc', train_data)\n",
    "else:\n",
    "    train_data = load_array(path+'train_data.bc')\n",
    "    \n",
    "if not os.path.exists(processed_data_path+'val_data.bc'):\n",
    "    val_data = get_data(val_path)\n",
    "    save_array(processed_data_path+'val_data.bc', val_data)\n",
    "else:\n",
    "    val_data = load_array(path+'val_data.bc')\n",
    "    \n",
    "if not os.path.exists(processed_data_path+'test_data.bc'):\n",
    "    test_data = get_data(test_path)\n",
    "    save_array(processed_data_path+'test_data.bc', test_data)\n",
    "else:\n",
    "    test_data = load_array(path+'test_data.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTune and Train VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Precompute output from VGG's 2nd to last layer and use it to train a linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pop last layer and set model.outputs = to that of the previously 2nd-to-last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "\n",
    "# model.layers[-1].outbound_nodes = [] ... this is not needed\n",
    "model.outputs = [model.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precompute output for update model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096)\n",
      "(300, 4096)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(processed_data_path+'train_features_ft.bc'):\n",
    "    train_features_ft = model.predict(train_data, batch_size)\n",
    "    val_features_ft = model.predict(val_data, batch_size)\n",
    "    \n",
    "    save_array(processed_data_path+'train_features_ft.bc', train_data)\n",
    "    save_array(processed_data_path+'val_features_ft.bc', val_features_ft)\n",
    "else:\n",
    "    train_features_ft = load_array(path+'train_features_ft.bc')\n",
    "    val_features_ft = load_array(path+'val_features_ft.bc')\n",
    "    \n",
    "print(train_features.shape)\n",
    "print(val_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a linear classifier using the precomputed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Train model after replacing last layer with a Dense layer having 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()\n",
    "model = VGG19(weights='imagenet', include_top=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = finetune(model, 10)\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
