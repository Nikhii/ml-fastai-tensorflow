{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# adds parent directory to python path so we can access code located there\n",
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path: sys.path.append(nb_dir)\n",
    "    \n",
    "# core imports\n",
    "from ohmeow_ml.keras_tf_util import *\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "    \n",
    "# configure autoreload to re-load changed modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "DATA_HOME_DIR = current_dir + '/data/'\n",
    "\n",
    "rebuild_from_data_download = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Copy a small amount of our data into a `sample` directory, with the exact same structure as our `train` directory -- this is *always* a good idea in *all* machine learning since we should do all of our initial testing using a dataset small enough that we never have to wait for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip training and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (rebuild_from_data_download == True):\n",
    "    # unzip kaggle imgs.zip -> /train and /test\n",
    "    with zipfile.ZipFile(DATA_HOME_DIR + 'imgs.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_HOME_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how many examples we have for each class in the training dataset and the overall number of images we have in test.\n",
    "\n",
    "** NOTE: ** There is a huge difference between the number of test images (~ 80k) and training images (~ 20k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images per class:\n",
      "c4 2326\n",
      "c5 2312\n",
      "c9 2129\n",
      "c8 1911\n",
      "c0 2489\n",
      "c1 2267\n",
      "c6 2325\n",
      "c3 2346\n",
      "c2 2317\n",
      "c7 2002\n",
      "\n",
      "# of test images: 79726\n"
     ]
    }
   ],
   "source": [
    "DATA_CLASSES = [ dir for dir in os.listdir(DATA_HOME_DIR+'train') ]\n",
    "\n",
    "print('# of training images per class:')\n",
    "for c in DATA_CLASSES:\n",
    "    print(c, len(glob(DATA_HOME_DIR+'train/' + c + '/*')))\n",
    "    \n",
    "print('')\n",
    "\n",
    "print('# of test images:',len(glob(DATA_HOME_DIR+'test/*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set aside the images of 30% of the subjects (drivers) as our validation set\n",
    "\n",
    "IMPORTANT: Per the competition rules ... \"The train and test data are split on the drivers, such that one driver can only appear on either train or test set\" ***AND SO*** we must do the same thing with our validatin set or we will get overly optimistic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take a look at our drivers\n",
    "df = pd.read_csv(DATA_HOME_DIR+'driver_imgs_list.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p015', 'p056', 'p026', 'p052', 'p050', 'p050', 'p016'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find individual subjects (drivers)\n",
    "df_subjects = df.groupby(by='subject')['img'].count()\n",
    "drivers = df_subjects.index.tolist()\n",
    "\n",
    "# split the train/val 70/30 (so 30% of the subjects will make up our validation set)\n",
    "val_n = math.floor(len(drivers) * 0.3)\n",
    "val_drivers = np.random.choice(drivers, val_n)\n",
    "val_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>p015</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_48693.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>p015</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44903.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>p015</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_58514.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>p015</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_62307.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>p015</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_83984.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject classname            img\n",
       "2424    p015        c0  img_48693.jpg\n",
       "2425    p015        c0  img_44903.jpg\n",
       "2426    p015        c0  img_58514.jpg\n",
       "2427    p015        c0  img_62307.jpg\n",
       "2428    p015        c0  img_83984.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df[df['subject'].isin(val_drivers)]\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation, test, and sample directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (rebuild_from_data_download == True):\n",
    "    # create the directory structure required for machine learning with keras\n",
    "    for c in DATA_CLASSES:\n",
    "        make_dir(DATA_HOME_DIR + 'sample/train/' + c)\n",
    "        make_dir(DATA_HOME_DIR + 'sample/valid/' + c)\n",
    "        make_dir(DATA_HOME_DIR + 'sample/test/unknown')\n",
    "        make_dir(DATA_HOME_DIR + 'valid/' + c)\n",
    "        \n",
    "    make_dir(DATA_HOME_DIR + 'test/unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move training, validation, and test data into appropriate sub-directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (rebuild_from_data_download == True):\n",
    "    # move VALIDATION datasets\n",
    "    for idx, row in df_val.iterrows():\n",
    "        f = \"{0}/{1}/{2}\".format(DATA_HOME_DIR+'train', row['classname'], row['img'])\n",
    "        shutil.move(f, \"{0}/{1}\".format(DATA_HOME_DIR+'valid', row['classname']))\n",
    "            \n",
    "    # move TEST images into /unknown subdirectory\n",
    "    for file in glob(DATA_HOME_DIR + 'test/*'):\n",
    "        shutil.move(file, DATA_HOME_DIR + 'test/unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy a subset of training, validation, and test data into approprite sub-directories under /sample folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (rebuild_from_data_download == True):\n",
    "    # create SAMPLE train and validation datasets\n",
    "    for c in DATA_CLASSES:\n",
    "        for file in py_random.sample(os.listdir(DATA_HOME_DIR + 'train/' + c), 150):\n",
    "            shutil.copy(DATA_HOME_DIR + 'train/' + c + '/' + file, DATA_HOME_DIR + 'sample/train/' + c)\n",
    "            \n",
    "    for c in DATA_CLASSES:\n",
    "        for file in py_random.sample(os.listdir(DATA_HOME_DIR + 'valid/' + c), 75):\n",
    "            shutil.copy(DATA_HOME_DIR + 'valid/' + c + '/' + file, DATA_HOME_DIR + 'sample/valid/' + c)\n",
    "            \n",
    "    for file in py_random.sample(os.listdir(DATA_HOME_DIR + 'test/unknown'), 500):\n",
    "        shutil.copy(DATA_HOME_DIR + 'test/unknown/' + file, DATA_HOME_DIR + 'sample/test/unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
